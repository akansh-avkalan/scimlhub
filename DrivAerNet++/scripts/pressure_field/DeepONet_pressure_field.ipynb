{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf8ef40",
   "metadata": {},
   "source": [
    "# Surrogate Model Surface pressure field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e965c8b",
   "metadata": {},
   "source": [
    "## DeepONet Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d11347",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56f4420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import os\n",
    "\n",
    "class DrivAerNetDeepONetDataset(Dataset):\n",
    "    def __init__(self, npz_dir, vtk_dir, global_stats_path=None, num_trunk_samples=4096, normalize_pressure=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            npz_dir: Folder containing the preprocessed .npz files (Branch data)\n",
    "            vtk_dir: Folder containing the raw .vtk/.vtm files (Trunk data)\n",
    "            global_stats_path: Path to 'pressure_stats.npz' (mean/std)\n",
    "            num_trunk_samples: Number of points to sample for TrunkNet\n",
    "            normalize_pressure: Boolean flag to toggle pressure normalization\n",
    "        \"\"\"\n",
    "        self.npz_files = sorted([f for f in os.listdir(npz_dir) if f.endswith('.npz')])\n",
    "        self.npz_dir = npz_dir\n",
    "        self.vtk_dir = vtk_dir\n",
    "        self.num_trunk_samples = num_trunk_samples\n",
    "        self.normalize_pressure = normalize_pressure\n",
    "        \n",
    "        # Load Global Statistics for Pressure\n",
    "        if self.normalize_pressure:\n",
    "            stats = np.load(global_stats_path)\n",
    "            self.global_mean = stats['mean']\n",
    "            self.global_std = stats['std']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.npz_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Load Preprocessed Branch Data\n",
    "        npz_path = os.path.join(self.npz_dir, self.npz_files[idx])\n",
    "        npz_data = np.load(npz_path)\n",
    "        \n",
    "        branch_points = npz_data['points']      # Already (4096, 3) and Normalized\n",
    "        pc_centroid = npz_data['centroid']      # To sync with Mesh\n",
    "        pc_scale = npz_data['scale']            # To sync with Mesh\n",
    "        \n",
    "        # 2. Load Raw Trunk Data (Mesh)\n",
    "        # Assuming filename is the same, e.g., 'car_001.npz' -> 'car_001.vtk'\n",
    "        vtk_filename = self.npz_files[idx].replace('.npz', '.vtk') \n",
    "        vtk_path = os.path.join(self.vtk_dir, vtk_filename)\n",
    "        \n",
    "        mesh = pv.read(vtk_path)\n",
    "        raw_coords = mesh.points\n",
    "        raw_pressure = mesh.point_data['p'] # Ensure key matches your VTK ('p' or 'pressure')\n",
    "\n",
    "        # 3. Random Sampling for Trunk\n",
    "        indices = np.random.choice(len(raw_coords), self.num_trunk_samples, replace=False)\n",
    "        sampled_coords = raw_coords[indices]\n",
    "        sampled_pressure = raw_pressure[indices]\n",
    "\n",
    "        # 4. Sync Trunk Coordinates with Branch Geometry\n",
    "        # We apply the EXACT same transform used for the Point Cloud\n",
    "        trunk_coords = (sampled_coords - pc_centroid) / pc_scale\n",
    "\n",
    "        # 5. Pressure Normalization (Toggleable)\n",
    "        if self.normalize_pressure:\n",
    "            target_pressure = (sampled_pressure - self.global_mean) / self.global_std\n",
    "        else:\n",
    "            target_pressure = sampled_pressure\n",
    "\n",
    "        # 6. Convert to Tensors\n",
    "        return {\n",
    "            \"branch_input\": torch.FloatTensor(branch_points),      # (4096, 3)\n",
    "            \"trunk_input\": torch.FloatTensor(trunk_coords),        # (2048, 3)\n",
    "            \"target\": torch.FloatTensor(target_pressure).unsqueeze(-1) # (2048, 1)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cf480d",
   "metadata": {},
   "source": [
    "## Split the data and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdc4d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_dataloaders(npz_dir, vtk_dir, stats_path, batch_size=4, split_ratio=(0.8, 0.1, 0.1)):\n",
    "    \"\"\"\n",
    "    Splits the dataset and returns Train, Val, and Test DataLoaders.\n",
    "    \"\"\"\n",
    "    # 1. Initialize the full dataset\n",
    "    full_dataset = DrivAerNetDeepONetDataset(\n",
    "        npz_dir=npz_dir,\n",
    "        vtk_dir=vtk_dir,\n",
    "        global_stats_path=stats_path,\n",
    "        normalize_pressure=True\n",
    "    )\n",
    "\n",
    "    # 2. Generate indices for splitting\n",
    "    dataset_size = len(full_dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    \n",
    "    train_size, val_size, test_size = split_ratio\n",
    "    \n",
    "    # Split: Train and (Val + Test)\n",
    "    train_idx, tmp_idx = train_test_split(\n",
    "        indices, train_size=train_size, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Split: Val and Test\n",
    "    relative_val_size = val_size / (val_size + test_size)\n",
    "    val_idx, test_idx = train_test_split(\n",
    "        tmp_idx, train_size=relative_val_size, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    # 3. Create Subsets\n",
    "    train_dataset = Subset(full_dataset, train_idx)\n",
    "    val_dataset = Subset(full_dataset, val_idx)\n",
    "    test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "    # 4. Create DataLoaders\n",
    "    # Note: num_workers > 0 allows CPU to load next batch while GPU processes current one\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "824c5fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 50\n",
      "Val batches: 7\n",
      "Test batches: 7\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "NPZ_PATH = \"02_dataset/car_pc_vtk\"\n",
    "VTK_PATH = \"02_dataset/car_pressure_field/F_D_WM_WW_1\"\n",
    "STATS_FILE = \"02_dataset/pressure_stats.npz\"\n",
    "BATCH_SIZE = 8 # Adjust based on your GPU VRAM\n",
    "\n",
    "# Get Loaders\n",
    "train_loader, val_loader, test_loader = get_dataloaders(\n",
    "    NPZ_PATH, VTK_PATH, STATS_FILE, batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b55e1e",
   "metadata": {},
   "source": [
    "## Model Architecture: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a119c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def index_points(points, idx):\n",
    "    \"\"\"Helper to index points based on FPS/Ball Query indices.\"\"\"\n",
    "    device = points.device\n",
    "    B = points.shape[0]\n",
    "    view_shape = list(idx.shape)\n",
    "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "    repeat_shape = list(idx.shape)\n",
    "    repeat_shape[0] = 1\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
    "    new_points = points[batch_indices, idx, :]\n",
    "    return new_points\n",
    "\n",
    "def farthest_point_sample(xyz, npoint):\n",
    "    \"\"\"Iterative Farthest Point Sampling to pick cluster centers.\"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)\n",
    "    distance = torch.ones(B, N).to(device) * 1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
    "    for i in range(npoint):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "    return centroids\n",
    "\n",
    "def query_ball_point(radius, nsample, xyz, new_xyz):\n",
    "    \"\"\"Grouping points within a fixed radius.\"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    _, S, _ = new_xyz.shape\n",
    "    group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat(B, S, 1)\n",
    "    sqdist = torch.sum((new_xyz.view(B, S, 1, 3) - xyz.view(B, 1, N, 3)) ** 2, -1)\n",
    "    group_idx[sqdist > radius ** 2] = N\n",
    "    group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]\n",
    "    group_first = group_idx[:, :, 0].view(B, S, 1).repeat(1, 1, nsample)\n",
    "    mask = group_idx == N\n",
    "    group_idx[mask] = group_first[mask]\n",
    "    return group_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c44ae5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetSetAbstraction(nn.Module):\n",
    "    def __init__(self, npoint, radius, nsample, in_channel, mlp):\n",
    "        super(PointNetSetAbstraction, self).__init__()\n",
    "        self.npoint = npoint\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
    "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "            \n",
    "    def forward(self, xyz, points):\n",
    "        \"\"\"\n",
    "        xyz: input points position data, [B, 3, N]\n",
    "        points: input points data, [B, D, N]\n",
    "        \"\"\"\n",
    "        # Switch to [B, N, 3] for sampling/grouping logic\n",
    "        xyz = xyz.permute(0, 2, 1)\n",
    "        if points is not None:\n",
    "            points = points.permute(0, 2, 1)\n",
    "\n",
    "        # 1. Sample and Group\n",
    "        new_xyz_idx = farthest_point_sample(xyz, self.npoint)\n",
    "        new_xyz = index_points(xyz, new_xyz_idx)\n",
    "        idx = query_ball_point(self.radius, self.nsample, xyz, new_xyz)\n",
    "        grouped_xyz = index_points(xyz, idx) # [B, npoint, nsample, 3]\n",
    "        \n",
    "        # 2. Make coordinates local to the cluster center\n",
    "        grouped_xyz_norm = grouped_xyz - new_xyz.view(xyz.shape[0], self.npoint, 1, 3)\n",
    "\n",
    "        # 3. Concatenate features\n",
    "        if points is not None:\n",
    "            grouped_points = index_points(points, idx)\n",
    "            # Combine local relative coords with existing features\n",
    "            new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1) # [B, npoint, nsample, 3+D]\n",
    "        else:\n",
    "            # For SA1: Combine local relative coords with global absolute coords\n",
    "            # This is where the \"6 channels\" come from (3 local + 3 global)\n",
    "            new_points = torch.cat([grouped_xyz_norm, grouped_xyz], dim=-1) # [B, npoint, nsample, 6]\n",
    "\n",
    "        # 4. Prepare for Conv2d: [B, Channels, nsample, npoint]\n",
    "        new_points = new_points.permute(0, 3, 2, 1) \n",
    "        \n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_points = F.relu(bn(conv(new_points)))\n",
    "\n",
    "        # 5. Max Pool over the samples\n",
    "        new_points = torch.max(new_points, 2)[0]\n",
    "        new_xyz = new_xyz.permute(0, 2, 1)\n",
    "        \n",
    "        return new_xyz, new_points\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ef997",
   "metadata": {},
   "source": [
    "### DeepONet Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fb27319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointDeepONet(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(PointDeepONet, self).__init__()\n",
    "        \n",
    "        # --- BRANCH NET (PointNet++) ---\n",
    "        # SA1: 4096 -> 1024 points\n",
    "        self.sa1 = PointNetSetAbstraction(npoint=1024, radius=0.1, nsample=32, in_channel=3+3, mlp=[64, 64, 128])\n",
    "        # SA2: 1024 -> 256 points\n",
    "        self.sa2 = PointNetSetAbstraction(npoint=256, radius=0.2, nsample=32, in_channel=128+3, mlp=[128, 128, 256])\n",
    "        # SA3: 256 -> 64 points\n",
    "        self.sa3 = PointNetSetAbstraction(npoint=64, radius=0.4, nsample=32, in_channel=256+3, mlp=[256, 512, 1024])\n",
    "        \n",
    "        self.branch_fc = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, latent_dim)\n",
    "        )\n",
    "\n",
    "        # --- TRUNK NET (MLP) ---\n",
    "        self.trunk_net = nn.Sequential(\n",
    "            nn.Linear(3, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, branch_xyz, trunk_xyz):\n",
    "        \"\"\"\n",
    "        branch_xyz: (B, 3, 4096) -> The sampled point cloud\n",
    "        trunk_xyz: (B, M, 3) -> The mesh query points\n",
    "        \"\"\"\n",
    "        B = branch_xyz.shape[0]\n",
    "        \n",
    "        # 1. Branch Pass\n",
    "        l1_xyz, l1_points = self.sa1(branch_xyz, None)\n",
    "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
    "        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n",
    "        \n",
    "        # Global Pooling over the remaining 64 points\n",
    "        branch_features = torch.max(l3_points, 2)[0] \n",
    "        branch_v = self.branch_fc(branch_features) # (B, latent_dim)\n",
    "\n",
    "        # 2. Trunk Pass\n",
    "        M = trunk_xyz.shape[1]\n",
    "        trunk_v = self.trunk_net(trunk_xyz.view(-1, 3))\n",
    "        trunk_v = trunk_v.view(B, M, -1) # (B, M, latent_dim)\n",
    "\n",
    "        # 3. Dot Product Fusion\n",
    "        # bg: Batch, Latent | bmg: Batch, Points, Latent -> bm: Batch, Points\n",
    "        out = torch.einsum('bg,bmg->bm', branch_v, trunk_v)\n",
    "        \n",
    "        return out.unsqueeze(-1) + self.bias # (B, M, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe1519f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Sanity Check on cuda ---\n",
      "Input Shapes: Branch torch.Size([4, 3, 4096]), Trunk torch.Size([4, 2048, 3])\n",
      "Output Shape: torch.Size([4, 2048, 1])\n",
      "✅ Forward Pass: Shape Correct.\n",
      "✅ Backward Pass: Gradient flow confirmed in both networks.\n",
      "✅ Permutation Invariance: Confirmed (Max Diff: 1.96e-05)\n",
      "\n",
      "--- All Sanity Checks Passed! ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def model_sanity_check():\n",
    "    # 1. Setup Parameters\n",
    "    batch_size = 4\n",
    "    num_branch_points = 4096\n",
    "    num_trunk_query_points = 2048\n",
    "    latent_dim = 128\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(f\"--- Starting Sanity Check on {device} ---\")\n",
    "\n",
    "    # 2. Initialize Model\n",
    "    model = PointDeepONet(latent_dim=latent_dim).to(device)\n",
    "    model.train()\n",
    "\n",
    "    # 3. Create Dummy Inputs (Mimicking our DataLoader)\n",
    "    # Branch: (B, 3, 4096) - Note the 3 is the second dim for SA layers\n",
    "    dummy_branch_pc = torch.randn(batch_size, 3, num_branch_points).to(device)\n",
    "    # Trunk: (B, 2048, 3)\n",
    "    dummy_trunk_coords = torch.randn(batch_size, num_trunk_query_points, 3).to(device)\n",
    "    # Target: (B, 2048, 1)\n",
    "    dummy_target = torch.randn(batch_size, num_trunk_query_points, 1).to(device)\n",
    "\n",
    "    print(f\"Input Shapes: Branch {dummy_branch_pc.shape}, Trunk {dummy_trunk_coords.shape}\")\n",
    "\n",
    "    # 4. Forward Pass\n",
    "    try:\n",
    "        output = model(dummy_branch_pc, dummy_trunk_coords)\n",
    "        print(f\"Output Shape: {output.shape}\")\n",
    "        \n",
    "        # Check 1: Output Shape Correctness\n",
    "        assert output.shape == (batch_size, num_trunk_query_points, 1), \"❌ Output shape mismatch!\"\n",
    "        print(\"✅ Forward Pass: Shape Correct.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Forward Pass Failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # 5. Backward Pass (Gradient Flow Check)\n",
    "    try:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        \n",
    "        loss = loss_fn(output, dummy_target)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Check if gradients exist in both nets\n",
    "        branch_grad = next(model.sa1.mlp_convs[0].parameters()).grad\n",
    "        trunk_grad = next(model.trunk_net[0].parameters()).grad\n",
    "        \n",
    "        assert branch_grad is not None, \"❌ No gradients in Branch Net!\"\n",
    "        assert trunk_grad is not None, \"❌ No gradients in Trunk Net!\"\n",
    "        \n",
    "        print(\"✅ Backward Pass: Gradient flow confirmed in both networks.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Backward Pass Failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # 6. Permutation Invariance Check\n",
    "    # If we shuffle the 4096 points, the branch output (and thus final output) should be the same\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        idx = torch.randperm(num_branch_points)\n",
    "        shuffled_branch_pc = dummy_branch_pc[:, :, idx]\n",
    "        \n",
    "        original_out = model(dummy_branch_pc, dummy_trunk_coords)\n",
    "        shuffled_out = model(shuffled_branch_pc, dummy_trunk_coords)\n",
    "        \n",
    "        # Check if the difference is negligible\n",
    "        diff = torch.abs(original_out - shuffled_out).max().item()\n",
    "        if diff < 1e-4:\n",
    "            print(f\"✅ Permutation Invariance: Confirmed (Max Diff: {diff:.2e})\")\n",
    "        else:\n",
    "            print(f\"⚠️ Permutation Invariance Warning: Max Diff: {diff:.2e}\")\n",
    "\n",
    "    print(\"\\n--- All Sanity Checks Passed! ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure all previous code (Utilities, SA Module, PointDeepONet) is in the same file or imported\n",
    "    model_sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c5607",
   "metadata": {},
   "source": [
    "## Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4770ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Utility to log progress to both console and a text file\n",
    "def log_message(message, log_file='logs/deepONet_03_not_normalized/train_log.txt'):\n",
    "    print(message)\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"[{time.ctime()}] {message}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a8409ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CHECKPOINT_DIR = '03_checkpoints/deepONet_03_not_normalized'\n",
    "LOG_FILE = 'logs/deepONet_03_not_normalized/train_log.txt'\n",
    "LATEST_CHECKPOINT = os.path.join(CHECKPOINT_DIR, 'latest_checkpoint.pth')\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "def initialize_training(model, optimizer, checkpoint_path):\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    if os.path.exists(checkpoint_path):\n",
    "        log_message(f\"Checking for checkpoint at {checkpoint_path}...\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "        log_message(f\"Successfully resumed from Epoch {start_epoch}\")\n",
    "    else:\n",
    "        log_message(\"No checkpoint found. Starting training from scratch.\")\n",
    "        \n",
    "    return start_epoch, best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea19cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, loader, optimizer, criterion, device, is_training=True):\n",
    "    if is_training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "        \n",
    "    total_loss = 0\n",
    "    desc = \"Train\" if is_training else \"Val\"\n",
    "    bar = tqdm(loader, desc=desc)\n",
    "\n",
    "    for batch in bar:\n",
    "        # Prepare inputs (Permute Branch for PointNet++ channels)\n",
    "        branch_in = batch['branch_input'].permute(0, 2, 1).to(device)\n",
    "        trunk_in = batch['trunk_input'].to(device)\n",
    "        targets = batch['target'].to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(is_training):\n",
    "            preds = model(branch_in, trunk_in)\n",
    "            loss = criterion(preds, targets)\n",
    "\n",
    "            if is_training:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        bar.set_postfix(mse=loss.item())\n",
    "\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3eee7fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting training from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.03it/s, mse=0.993]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train 8.996874 | Val 0.986015 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.918]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train 0.953619 | Val 0.928972 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.929]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.87] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train 0.918172 | Val 0.904115 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.891]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train 0.891813 | Val 0.882201 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.01s/it, mse=0.851]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.82s/it, mse=0.83] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train 0.875503 | Val 0.862747 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:51<00:00,  1.02s/it, mse=0.862]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train 0.856197 | Val 0.835485 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.02it/s, mse=0.828]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.77s/it, mse=0.738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train 0.890080 | Val 0.837254 | LR 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.02it/s, mse=0.792]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train 0.819450 | Val 0.810749 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.00s/it, mse=0.809]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train 0.780515 | Val 0.819619 | LR 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.788]\n",
      "Val: 100%|██████████| 7/7 [00:13<00:00,  1.86s/it, mse=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train 0.811559 | Val 0.766092 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.03it/s, mse=0.722]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train 0.753347 | Val 0.740618 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.02it/s, mse=0.714]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train 0.743871 | Val 0.727699 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.737]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train 0.745075 | Val 0.718447 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.693]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train 0.724842 | Val 0.731485 | LR 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.02it/s, mse=0.744]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train 0.730750 | Val 0.738896 | LR 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.755]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train 0.721655 | Val 0.738542 | LR 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.01s/it, mse=0.944]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train 0.720398 | Val 0.700993 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.713]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train 0.711639 | Val 0.708048 | LR 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.01s/it, mse=0.695]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.85s/it, mse=0.664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train 0.696576 | Val 0.701563 | LR 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.65] \n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.81s/it, mse=0.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train 0.689007 | Val 0.695669 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.01s/it, mse=0.691]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train 0.697524 | Val 0.694683 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.633]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train 0.672189 | Val 0.692178 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.693]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train 0.684514 | Val 0.687056 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.736]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train 0.677194 | Val 0.665272 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:51<00:00,  1.02s/it, mse=0.658]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train 0.655818 | Val 0.649028 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.654]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.82s/it, mse=0.537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train 0.647751 | Val 0.621878 | LR 1.00e-03\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:51<00:00,  1.03s/it, mse=0.66] \n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.83s/it, mse=0.622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train 0.640581 | Val 0.660213 | LR 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:51<00:00,  1.04s/it, mse=0.626]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.77s/it, mse=0.606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train 0.630695 | Val 0.629014 | LR 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.646]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train 0.648768 | Val 0.651959 | LR 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.624]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train 0.632761 | Val 0.622234 | LR 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.00it/s, mse=0.614]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train 0.616800 | Val 0.622568 | LR 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.589]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train 0.624168 | Val 0.657315 | LR 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.62] \n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.78s/it, mse=0.577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train 0.633051 | Val 0.618173 | LR 5.00e-04\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.03it/s, mse=0.612]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.77s/it, mse=0.556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train 0.614945 | Val 0.592830 | LR 5.00e-04\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.57] \n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.85s/it, mse=0.513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train 0.608651 | Val 0.591847 | LR 5.00e-04\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.576]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.80s/it, mse=0.647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train 0.613777 | Val 0.613670 | LR 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.619]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train 0.601845 | Val 0.603868 | LR 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.604]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train 0.606860 | Val 0.590269 | LR 5.00e-04\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.594]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.54] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train 0.613260 | Val 0.590655 | LR 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.03it/s, mse=0.599]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train 0.595897 | Val 0.597316 | LR 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.573]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.84s/it, mse=0.6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train 0.600016 | Val 0.606246 | LR 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.01s/it, mse=0.572]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Train 0.598003 | Val 0.590732 | LR 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.551]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Train 0.595637 | Val 0.599046 | LR 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.573]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.55] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Train 0.590508 | Val 0.590427 | LR 2.50e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.04it/s, mse=0.583]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train 0.589068 | Val 0.597183 | LR 2.50e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.599]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.77s/it, mse=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train 0.600671 | Val 0.567949 | LR 2.50e-04\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.568]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train 0.593540 | Val 0.580949 | LR 2.50e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.01s/it, mse=0.608]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train 0.584052 | Val 0.581486 | LR 2.50e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.02s/it, mse=0.566]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train 0.582484 | Val 0.587523 | LR 2.50e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.613]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train 0.577074 | Val 0.579551 | LR 2.50e-04\n",
      "System: 10-Epoch Periodic Checkpoint Saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.02s/it, mse=0.53] \n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Train 0.574022 | Val 0.579881 | LR 2.50e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.02it/s, mse=0.591]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Train 0.575099 | Val 0.592815 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.02it/s, mse=0.567]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Train 0.577680 | Val 0.576882 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.566]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.77s/it, mse=0.534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Train 0.575253 | Val 0.563757 | LR 1.25e-04\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.01s/it, mse=0.575]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train 0.574096 | Val 0.575149 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:51<00:00,  1.02s/it, mse=0.548]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Train 0.570441 | Val 0.571284 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.02it/s, mse=0.563]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train 0.571860 | Val 0.579755 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.555]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.79s/it, mse=0.531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train 0.573088 | Val 0.565052 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.00it/s, mse=0.569]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.84s/it, mse=0.521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Train 0.566322 | Val 0.564190 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.00it/s, mse=0.556]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.542]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train 0.565907 | Val 0.555628 | LR 1.25e-04\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.03it/s, mse=0.566]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Train 0.572634 | Val 0.604843 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.03it/s, mse=0.562]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Train 0.567773 | Val 0.576886 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.02it/s, mse=0.585]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.56] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Train 0.561403 | Val 0.568596 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:51<00:00,  1.04s/it, mse=0.583]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.77s/it, mse=0.578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Train 0.565123 | Val 0.568289 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.01s/it, mse=0.552]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.82s/it, mse=0.52] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Train 0.574481 | Val 0.553127 | LR 1.25e-04\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:51<00:00,  1.02s/it, mse=0.528]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.84s/it, mse=0.514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Train 0.562611 | Val 0.564228 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.00it/s, mse=0.574]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.83s/it, mse=0.499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Train 0.558535 | Val 0.558391 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.526]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.77s/it, mse=0.503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Train 0.556574 | Val 0.570761 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.562]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Train 0.570189 | Val 0.558478 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.00s/it, mse=0.547]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Train 0.555550 | Val 0.562298 | LR 1.25e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.01s/it, mse=0.557]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.83s/it, mse=0.581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Train 0.549735 | Val 0.567011 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.55] \n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.84s/it, mse=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Train 0.551693 | Val 0.549307 | LR 6.25e-05\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.01s/it, mse=0.58] \n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Train 0.560999 | Val 0.565347 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.537]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.84s/it, mse=0.522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Train 0.553264 | Val 0.550945 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.02it/s, mse=0.529]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.77s/it, mse=0.535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Train 0.557621 | Val 0.547094 | LR 6.25e-05\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.542]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Train 0.552310 | Val 0.552901 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.573]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.78s/it, mse=0.529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Train 0.551961 | Val 0.549644 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.03it/s, mse=0.541]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Train 0.553740 | Val 0.582191 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.533]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: Train 0.557437 | Val 0.547991 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.03it/s, mse=0.517]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.53] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Train 0.550582 | Val 0.545796 | LR 6.25e-05\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:51<00:00,  1.03s/it, mse=0.506]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.85s/it, mse=0.521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Train 0.556645 | Val 0.553456 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:51<00:00,  1.02s/it, mse=0.527]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Train 0.552623 | Val 0.553970 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.02it/s, mse=0.534]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: Train 0.554173 | Val 0.562749 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.02it/s, mse=0.53] \n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: Train 0.545819 | Val 0.554585 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.566]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Train 0.545905 | Val 0.545133 | LR 6.25e-05\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.518]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: Train 0.547404 | Val 0.548114 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.535]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Train 0.545162 | Val 0.568415 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:50<00:00,  1.01s/it, mse=0.553]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Train 0.550530 | Val 0.537140 | LR 6.25e-05\n",
      "System: Best Model updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.03it/s, mse=0.548]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Train 0.560065 | Val 0.549147 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.551]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.85s/it, mse=0.535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train 0.540512 | Val 0.541663 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.553]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.78s/it, mse=0.531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Train 0.547253 | Val 0.543681 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.02it/s, mse=0.534]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.77s/it, mse=0.519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Train 0.547161 | Val 0.541004 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.514]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.78s/it, mse=0.546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Train 0.540965 | Val 0.548010 | LR 6.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:48<00:00,  1.02it/s, mse=0.558]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.77s/it, mse=0.568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Train 0.553375 | Val 0.560217 | LR 3.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.527]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Train 0.557884 | Val 0.551792 | LR 3.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:51<00:00,  1.03s/it, mse=0.521]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it, mse=0.542]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: Train 0.544411 | Val 0.540419 | LR 3.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:51<00:00,  1.02s/it, mse=0.525]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.78s/it, mse=0.517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Train 0.556600 | Val 0.542374 | LR 3.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.51] \n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it, mse=0.512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: Train 0.539373 | Val 0.540454 | LR 3.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.01it/s, mse=0.576]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it, mse=0.557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Train 0.543801 | Val 0.540869 | LR 3.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, mse=0.562]\n",
      "Val: 100%|██████████| 7/7 [00:12<00:00,  1.77s/it, mse=0.544]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Train 0.552631 | Val 0.543192 | LR 1.56e-05\n",
      "System: 10-Epoch Periodic Checkpoint Saved.\n",
      "Training Complete. Final model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Model, Optimizer, and Scheduler\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PointDeepONet(latent_dim=256).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Get state\n",
    "start_epoch, best_val_loss = initialize_training(model, optimizer, LATEST_CHECKPOINT)\n",
    "\n",
    "# Main Loop\n",
    "NUM_EPOCHS = 100\n",
    "for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "    # 1. Train and Validate\n",
    "    avg_train_loss = run_epoch(model, train_loader, optimizer, criterion, device, is_training=True)\n",
    "    avg_val_loss = run_epoch(model, val_loader, optimizer, criterion, device, is_training=False)\n",
    "    \n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    # 2. Log Results\n",
    "    log_msg = f\"Epoch {epoch+1}: Train {avg_train_loss:.6f} | Val {avg_val_loss:.6f} | LR {optimizer.param_groups[0]['lr']:.2e}\"\n",
    "    log_message(log_msg, LOG_FILE)\n",
    "\n",
    "    # 3. Save \"Latest\" Checkpoint (Every Epoch for safety)\n",
    "    checkpoint_state = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_val_loss': best_val_loss,\n",
    "    }\n",
    "    torch.save(checkpoint_state, LATEST_CHECKPOINT)\n",
    "\n",
    "    # 4. Save Periodic Checkpoint (Every 10 Epochs)\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        periodic_path = os.path.join(CHECKPOINT_DIR, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "        torch.save(checkpoint_state, periodic_path)\n",
    "        log_message(f\"System: 10-Epoch Periodic Checkpoint Saved.\")\n",
    "\n",
    "    # 5. Save \"Best\" Model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, 'best_model.pth'))\n",
    "        log_message(\"System: Best Model updated.\")\n",
    "\n",
    "# Final Save after all epochs\n",
    "torch.save(model.state_dict(), \"final_point_deeponet.pth\")\n",
    "log_message(\"Training Complete. Final model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87242811",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2cbffdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from 03_checkpoints/deepONet_03/best_model.pth\n",
      "Global Stats - Mean: -93.65, Std: 114.89\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 1. Re-initialize the model architecture\n",
    "model = PointDeepONet(latent_dim=256).to(device)\n",
    "\n",
    "# 2. Load the trained weights\n",
    "MODEL_PATH = \"03_checkpoints/deepONet_03/best_model.pth\" # or \"final_point_deeponet.pth\"\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 3. Load Global Stats for Denormalization\n",
    "stats = np.load(\"pressure_stats.npz\")\n",
    "global_mean = stats['mean']\n",
    "global_std = stats['std']\n",
    "\n",
    "print(f\"Model loaded from {MODEL_PATH}\")\n",
    "print(f\"Global Stats - Mean: {global_mean:.2f}, Std: {global_std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00a8bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pressure(model, batch, device, mean, std):\n",
    "    \"\"\"\n",
    "    Takes a batch from the DataLoader and returns denormalized predictions and targets.\n",
    "    \"\"\"\n",
    "    # 1. Get inputs and move to device\n",
    "    # (B, 4096, 3) -> (B, 3, 4096) for PointNet++\n",
    "    branch_in = batch['branch_input'].permute(0, 2, 1).to(device)\n",
    "    trunk_in = batch['trunk_input'].to(device)\n",
    "    targets_norm = batch['target'].to(device)\n",
    "\n",
    "    # 2. Model Prediction (Output is normalized)\n",
    "    with torch.no_grad():\n",
    "        preds_norm = model(branch_in, trunk_in)\n",
    "\n",
    "    # 3. Denormalize: P_real = (P_norm * std) + mean\n",
    "    preds_real = (preds_norm.cpu().numpy() * std) + mean\n",
    "    targets_real = (targets_norm.cpu().numpy() * std) + mean\n",
    "\n",
    "    return preds_real, targets_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e48ad3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inference Results (Batch Size: 8) ---\n",
      "Mean Absolute Error: 47.09 Pa\n",
      "Max Error in Batch: 1053.46 Pa\n",
      "\n",
      "Sample 0, Point 0 Comparison:\n",
      "Predicted: -200.80 Pa\n",
      "Ground Truth: -224.77 Pa\n"
     ]
    }
   ],
   "source": [
    "# Pick a batch from the test loader\n",
    "test_batch = next(iter(test_loader))\n",
    "\n",
    "# Run Inference\n",
    "preds, targets = predict_pressure(model, test_batch, device, global_mean, global_std)\n",
    "\n",
    "# Calculate Errors (MAE and Max Error in Pascals)\n",
    "abs_error = np.abs(preds - targets)\n",
    "mae_pascals = np.mean(abs_error)\n",
    "max_error_pascals = np.max(abs_error)\n",
    "\n",
    "print(f\"--- Inference Results (Batch Size: {preds.shape[0]}) ---\")\n",
    "print(f\"Mean Absolute Error: {mae_pascals:.2f} Pa\")\n",
    "print(f\"Max Error in Batch: {max_error_pascals:.2f} Pa\")\n",
    "\n",
    "# Check a single point comparison\n",
    "sample_idx = 0\n",
    "point_idx = 0\n",
    "print(f\"\\nSample 0, Point 0 Comparison:\")\n",
    "print(f\"Predicted: {preds[sample_idx, point_idx, 0]:.2f} Pa\")\n",
    "print(f\"Ground Truth: {targets[sample_idx, point_idx, 0]:.2f} Pa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd5d08",
   "metadata": {},
   "source": [
    "--- Inference Results (Batch Size: 8) ---\n",
    "\n",
    "Mean Absolute Error: 52.13 Pa\n",
    "\n",
    "Max Error in Batch: 842.20 Pa\n",
    "\n",
    "\n",
    "\n",
    "Sample 0, Point 0 Comparison:\n",
    "\n",
    "Predicted: -111.99 Pa\n",
    "\n",
    "Ground Truth: -44.50 Pa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3134b8",
   "metadata": {},
   "source": [
    "--- Inference Results (Batch Size: 8) Second time ---\n",
    "\n",
    "Mean Absolute Error: 48.44 Pa\n",
    "\n",
    "Max Error in Batch: 1136.48 Pa\n",
    "\n",
    "\n",
    "Sample 0, Point 0 Comparison:\n",
    "Predicted: -84.42 Pa\n",
    "\n",
    "Ground Truth: -79.92 Pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "180a9140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inference Results (Batch Size: 8) ---\n",
      "Mean Absolute Error: 48.18 Pa\n",
      "Max Error in Batch: 1032.96 Pa\n",
      "\n",
      "Sample 0, Point 0 Comparison:\n",
      "Predicted: -192.34 Pa\n",
      "Ground Truth: -119.14 Pa\n"
     ]
    }
   ],
   "source": [
    "# Pick a batch from the test loader\n",
    "test_batch = next(iter(test_loader))\n",
    "\n",
    "# Run Inference\n",
    "preds, targets = predict_pressure(model, test_batch, device, global_mean, global_std)\n",
    "\n",
    "# Calculate Errors (MAE and Max Error in Pascals)\n",
    "abs_error = np.abs(preds - targets)\n",
    "mae_pascals = np.mean(abs_error)\n",
    "max_error_pascals = np.max(abs_error)\n",
    "\n",
    "print(f\"--- Inference Results (Batch Size: {preds.shape[0]}) ---\")\n",
    "print(f\"Mean Absolute Error: {mae_pascals:.2f} Pa\")\n",
    "print(f\"Max Error in Batch: {max_error_pascals:.2f} Pa\")\n",
    "\n",
    "# Check a single point comparison\n",
    "sample_idx = 0\n",
    "point_idx = 0\n",
    "print(f\"\\nSample 0, Point 0 Comparison:\")\n",
    "print(f\"Predicted: {preds[sample_idx, point_idx, 0]:.2f} Pa\")\n",
    "print(f\"Ground Truth: {targets[sample_idx, point_idx, 0]:.2f} Pa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c305ddc",
   "metadata": {},
   "source": [
    "--- Inference Results (Batch Size: 8) ---\n",
    "\n",
    "Mean Absolute Error: 52.12 Pa\n",
    "\n",
    "Max Error in Batch: 910.79 Pa\n",
    "\n",
    "Sample 0, Point 0 Comparison:\n",
    "\n",
    "Predicted: -131.98 Pa\n",
    "\n",
    "Ground Truth: -64.42 Pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2328c8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to prediction_output_deNorm_epoch.vtp\n"
     ]
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "def save_prediction_vtk(coords, preds, targets, filename=\"prediction_output_deNorm_epoch.vtp\"):\n",
    "    \"\"\"\n",
    "    Saves the predicted points as a VTK file for ParaView.\n",
    "    coords: (M, 3), preds: (M, 1), targets: (M, 1)\n",
    "    \"\"\"\n",
    "    # Create a point cloud mesh\n",
    "    point_cloud = pv.PolyData(coords)\n",
    "    point_cloud[\"Predicted_Pressure\"] = preds.flatten()\n",
    "    point_cloud[\"Actual_Pressure\"] = targets.flatten()\n",
    "    point_cloud[\"Error\"] = np.abs(preds - targets).flatten()\n",
    "    \n",
    "    point_cloud.save(filename)\n",
    "    print(f\"Visualization saved to {filename}\")\n",
    "\n",
    "# Save the first car in the batch\n",
    "# Note: coords must be the original raw coordinates or the synced normalized ones\n",
    "save_prediction_vtk(test_batch['trunk_input'][0].numpy(), preds[0], targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "445b89a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to prediction_output_200_epoch_2.vtp\n"
     ]
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "def save_prediction_vtk(coords, preds, targets, filename=\"prediction_output_200_epoch_2.vtp\"):\n",
    "    \"\"\"\n",
    "    Saves the predicted points as a VTK file for ParaView.\n",
    "    coords: (M, 3), preds: (M, 1), targets: (M, 1)\n",
    "    \"\"\"\n",
    "    # Create a point cloud mesh\n",
    "    point_cloud = pv.PolyData(coords)\n",
    "    point_cloud[\"Predicted_Pressure\"] = preds.flatten()\n",
    "    point_cloud[\"Actual_Pressure\"] = targets.flatten()\n",
    "    point_cloud[\"Error\"] = np.abs(preds - targets).flatten()\n",
    "    \n",
    "    point_cloud.save(filename)\n",
    "    print(f\"Visualization saved to {filename}\")\n",
    "\n",
    "# Save the first car in the batch\n",
    "# Note: coords must be the original raw coordinates or the synced normalized ones\n",
    "save_prediction_vtk(test_batch['trunk_input'][0].numpy(), preds[0], targets[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesh_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
